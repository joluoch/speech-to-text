{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import math, random\r\n",
    "import torch\r\n",
    "import torchaudio\r\n",
    "from torchaudio import transforms\r\n",
    "from IPython.display import Audio"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\r\n",
    "# used to load audio file\r\n",
    "#specifying sample rate will resize all the files i.e Audio will be automatically resampled to the given rate\r\n",
    "class Loader:\r\n",
    "  def __init__(self, sample_rate,duration,mono):\r\n",
    "    self.sample_rate=sample_rate\r\n",
    "    self.duration=duration\r\n",
    "    self.mono=mono\r\n",
    "    self.channel = 2\r\n",
    "\r\n",
    "\r\n",
    "  def load(self,filepath):\r\n",
    "    sig, sr = torchaudio.load(filepath)\r\n",
    "    aud = sig, sr\r\n",
    "    return aud\r\n",
    "\r\n",
    "  #before using this function kindly change your file paths for it to work\r\n",
    "\r\n",
    "\r\n",
    "  def rechannel(self, aud):    #convert mono to stereo\r\n",
    "    # aud=self.aud\r\n",
    "    sig, sr = aud\r\n",
    "  \r\n",
    "\r\n",
    "    if (sig.shape[0] == self.channel):\r\n",
    "      # Nothing to do\r\n",
    "      return self.aud\r\n",
    "\r\n",
    "    if (self.channel == 1):\r\n",
    "      # Convert from stereo to mono by selecting only the first channel\r\n",
    "      resig = sig[:1, :]\r\n",
    "    else:\r\n",
    "      # Convert from mono to stereo by duplicating the first channel\r\n",
    "      resig = torch.cat([sig, sig])\r\n",
    "\r\n",
    "    aud = resig, sr\r\n",
    "  def resample(self,aud):                    #standardize sample rate\r\n",
    "    sig, sr = aud\r\n",
    "    \r\n",
    "    if (sr == self.sample_rate):\r\n",
    "      # Nothing to do\r\n",
    "      return aud\r\n",
    "\r\n",
    "    num_channels = sig.shape[0]\r\n",
    "    # Resample first channel\r\n",
    "    resig = torchaudio.transforms.Resample(sr, self.sample_rate)(sig[:1,:])\r\n",
    "    if (num_channels > 1):\r\n",
    "      # Resample the second channel and merge both channels\r\n",
    "      retwo = torchaudio.transforms.Resample(sr, self.sample_rate)(sig[1:,:])\r\n",
    "      resig = torch.cat([resig, retwo])\r\n",
    "      aud = resig, self.sample_rate\r\n",
    "    return aud\r\n",
    "\r\n",
    "  # ----------------------------\r\n",
    "  # Pad (or truncate) the signal to a fixed length 'max_ms' in milliseconds\r\n",
    "  # ----------------------------\r\n",
    "  def pad_trunc(self,aud):\r\n",
    "    sig, sr = aud\r\n",
    "    num_rows, sig_len = sig.shape\r\n",
    "    max_len = sr//1000 * self.duration\r\n",
    "\r\n",
    "    if (sig_len > max_len):\r\n",
    "      # Truncate the signal to the given length\r\n",
    "      sig = sig[:,:max_len]\r\n",
    "\r\n",
    "    elif (sig_len < max_len):\r\n",
    "      # Length of padding to add at the beginning and end of the signal\r\n",
    "      pad_begin_len = random.randint(0, max_len - sig_len)\r\n",
    "      pad_end_len = max_len - sig_len - pad_begin_len\r\n",
    "\r\n",
    "      # Pad with 0s\r\n",
    "      pad_begin = torch.zeros((num_rows, pad_begin_len))\r\n",
    "      pad_end = torch.zeros((num_rows, pad_end_len))\r\n",
    "\r\n",
    "      sig = torch.cat((pad_begin, sig, pad_end), 1)\r\n",
    "      aud = sig, sr\r\n",
    "    return aud\r\n",
    "      # ----------------------------\r\n",
    "  # Shifts the signal to the left or right by some percent. Values at the end\r\n",
    "  # are 'wrapped around' to the start of the transformed signal.\r\n",
    "  # ----------------------------\r\n",
    " \r\n",
    "  def time_shift(aud, shift_limit):\r\n",
    "    sig,sr = aud\r\n",
    "    _, sig_len = sig.shape\r\n",
    "    shift_amt = int(random.random() * shift_limit * sig_len)\r\n",
    "    aud=sig.roll(shift_amt), sr\r\n",
    "    return aud\r\n",
    "    # ----------------------------\r\n",
    "  # Generate a Spectrogram\r\n",
    "  # ----------------------------\r\n",
    " \r\n",
    "  def spectro_gram(aud, n_mels=64, n_fft=1024, hop_len=None):\r\n",
    "    sig,sr = aud\r\n",
    "    top_db = 80\r\n",
    "\r\n",
    "    # spec has shape [channel, n_mels, time], where channel is mono, stereo etc\r\n",
    "    spec = transforms.MelSpectrogram(sr, n_fft=n_fft, hop_length=hop_len, n_mels=n_mels)(sig)\r\n",
    "\r\n",
    "    # Convert to decibels\r\n",
    "    spec = transforms.AmplitudeToDB(top_db=top_db)(spec)\r\n",
    "    return (spec)\r\n",
    "\r\n",
    "    # ----------------------------\r\n",
    "  # Augment the Spectrogram by masking out some sections of it in both the frequency\r\n",
    "  # dimension (ie. horizontal bars) and the time dimension (vertical bars) to prevent\r\n",
    "  # overfitting and to help the model generalise better. The masked sections are\r\n",
    "  # replaced with the mean value.\r\n",
    "  # ----------------------------\r\n",
    "  def spectro_augment(spec, max_mask_pct=0.1, n_freq_masks=1, n_time_masks=1):\r\n",
    "    _, n_mels, n_steps = spec.shape\r\n",
    "    mask_value = spec.mean()\r\n",
    "    aug_spec = spec\r\n",
    "\r\n",
    "    freq_mask_param = max_mask_pct * n_mels\r\n",
    "    for _ in range(n_freq_masks):\r\n",
    "      aug_spec = transforms.FrequencyMasking(freq_mask_param)(aug_spec, mask_value)\r\n",
    "\r\n",
    "    time_mask_param = max_mask_pct * n_steps\r\n",
    "    for _ in range(n_time_masks):\r\n",
    "      aug_spec = transforms.TimeMasking(time_mask_param)(aug_spec, mask_value)\r\n",
    "\r\n",
    "    return aug_spec"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class PreprocessingPipeline:\r\n",
    "\r\n",
    "    \r\n",
    "  '''Processes audio files in a directory by applying the following steps\r\n",
    "    1. Load the data, convert to stereo and resample sampling rate\r\n",
    "    2. Pad the audio\r\n",
    "  '''\r\n",
    "  def __init__(self):\r\n",
    "        self.padder=None\r\n",
    "        self._loader=None\r\n",
    "\r\n",
    "\r\n",
    "  def process(self,audio_files_directory):\r\n",
    "        for root, directories, files in os.walk(audio_files_directory):\r\n",
    "            for filename in files:\r\n",
    "                filepath = os.path.join(root, filename)\r\n",
    "                self._process_file(filepath)\r\n",
    "                print(f\"Processed file {filepath}\")\r\n",
    "                self._convert_mfcc(filepath)\r\n",
    "    \r\n",
    "  def _process_file(self,filepath):     \r\n",
    "        signal=self.loader.load(filepath)\r\n",
    "        signal = self.loader.make_stereo(signal)\r\n",
    "        signal = self.loader.resample(signal)\r\n",
    "        signal= self.loader.pad_trunc(signal)\r\n",
    "        signal= self.loader.time_shift(signal)\r\n",
    "        "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}